{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score, mean_squared_error, log_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel(\"/usr/input/flipr-hackathon-dataset/Train_dataset.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop([\"Name\", \"Designation\",],axis = 1)\n",
    "data = data.loc[~data.iloc[:,[1,2,3,5,6,9,12,13,]].isnull().any(axis=1)]\n",
    "y = data[\"Infect_Prob\"]\n",
    "data = data.drop([\"Infect_Prob\"], axis = 1)\n",
    "#y = (y >= 50).astype(\"float64\")\n",
    "y /= 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the columns with the categorical features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = [1,2,3,5,6,9,12,13,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert into one-hot representation for the neural network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_one_hot = pd.get_dummies(data = data, columns = data.columns[cat_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill in the missing values using the mean of each columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_data = data_one_hot.fillna(data.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(imputed_data.values, y, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([layers.Dense(8, activation='relu', input_dim=50, kernel_regularizer=keras.regularizers.l2(0.01)), \\\n",
    "                          layers.Dropout(0.2), \\\n",
    "                          layers.Dense(4, activation='relu',  kernel_regularizer=keras.regularizers.l2(0.01)), \\\n",
    "                          layers.Dropout(0.2), \\\n",
    "                          layers.Dense(1, activation = \"linear\"), \\\n",
    "                         ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = \"adam\", loss = \"mean_squared_error\", metrics = [\"mse\"])\n",
    "# use early stopping\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience = 10)\n",
    "# save the best model\n",
    "mc = ModelCheckpoint('best_model.h5', monitor='val_mse', mode='min', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7248 samples, validate on 2417 samples\n",
      "Epoch 1/1000\n",
      "7072/7248 [============================>.] - ETA: 0s - loss: 0.7663 - mse: 0.6073\n",
      "Epoch 00001: val_mse improved from inf to 0.13313, saving model to best_model.h5\n",
      "7248/7248 [==============================] - 1s 202us/sample - loss: 0.7543 - mse: 0.5957 - val_loss: 0.2733 - val_mse: 0.1331\n",
      "Epoch 2/1000\n",
      "7136/7248 [============================>.] - ETA: 0s - loss: 0.2148 - mse: 0.0910\n",
      "Epoch 00002: val_mse improved from 0.13313 to 0.03277, saving model to best_model.h5\n",
      "7248/7248 [==============================] - 1s 76us/sample - loss: 0.2139 - mse: 0.0903 - val_loss: 0.1391 - val_mse: 0.0328\n",
      "Epoch 3/1000\n",
      "6400/7248 [=========================>....] - ETA: 0s - loss: 0.1275 - mse: 0.0356\n",
      "Epoch 00003: val_mse improved from 0.03277 to 0.01725, saving model to best_model.h5\n",
      "7248/7248 [==============================] - 1s 75us/sample - loss: 0.1249 - mse: 0.0348 - val_loss: 0.0923 - val_mse: 0.0172\n",
      "Epoch 4/1000\n",
      "7136/7248 [============================>.] - ETA: 0s - loss: 0.0830 - mse: 0.0198\n",
      "Epoch 00004: val_mse improved from 0.01725 to 0.01214, saving model to best_model.h5\n",
      "7248/7248 [==============================] - 1s 76us/sample - loss: 0.0828 - mse: 0.0198 - val_loss: 0.0644 - val_mse: 0.0121\n",
      "Epoch 5/1000\n",
      "7232/7248 [============================>.] - ETA: 0s - loss: 0.0586 - mse: 0.0146\n",
      "Epoch 00005: val_mse improved from 0.01214 to 0.01033, saving model to best_model.h5\n",
      "7248/7248 [==============================] - 1s 76us/sample - loss: 0.0586 - mse: 0.0146 - val_loss: 0.0470 - val_mse: 0.0103\n",
      "Epoch 6/1000\n",
      "7136/7248 [============================>.] - ETA: 0s - loss: 0.0434 - mse: 0.0121\n",
      "Epoch 00006: val_mse improved from 0.01033 to 0.00978, saving model to best_model.h5\n",
      "7248/7248 [==============================] - 1s 77us/sample - loss: 0.0433 - mse: 0.0121 - val_loss: 0.0361 - val_mse: 0.0098\n",
      "Epoch 7/1000\n",
      "6336/7248 [=========================>....] - ETA: 0s - loss: 0.0343 - mse: 0.0112\n",
      "Epoch 00007: val_mse improved from 0.00978 to 0.00965, saving model to best_model.h5\n",
      "7248/7248 [==============================] - 1s 74us/sample - loss: 0.0339 - mse: 0.0112 - val_loss: 0.0292 - val_mse: 0.0097\n",
      "Epoch 8/1000\n",
      "7072/7248 [============================>.] - ETA: 0s - loss: 0.0275 - mse: 0.0104\n",
      "Epoch 00008: val_mse improved from 0.00965 to 0.00962, saving model to best_model.h5\n",
      "7248/7248 [==============================] - 1s 76us/sample - loss: 0.0275 - mse: 0.0104 - val_loss: 0.0245 - val_mse: 0.0096\n",
      "Epoch 9/1000\n",
      "7200/7248 [============================>.] - ETA: 0s - loss: 0.0234 - mse: 0.0102\n",
      "Epoch 00009: val_mse did not improve from 0.00962\n",
      "7248/7248 [==============================] - 1s 73us/sample - loss: 0.0233 - mse: 0.0102 - val_loss: 0.0212 - val_mse: 0.0096\n",
      "Epoch 10/1000\n",
      "7040/7248 [============================>.] - ETA: 0s - loss: 0.0203 - mse: 0.0099\n",
      "Epoch 00010: val_mse did not improve from 0.00962\n",
      "7248/7248 [==============================] - 1s 74us/sample - loss: 0.0202 - mse: 0.0099 - val_loss: 0.0188 - val_mse: 0.0097\n",
      "Epoch 11/1000\n",
      "7168/7248 [============================>.] - ETA: 0s - loss: 0.0179 - mse: 0.0097\n",
      "Epoch 00011: val_mse did not improve from 0.00962\n",
      "7248/7248 [==============================] - 1s 74us/sample - loss: 0.0179 - mse: 0.0098 - val_loss: 0.0170 - val_mse: 0.0097\n",
      "Epoch 12/1000\n",
      "6464/7248 [=========================>....] - ETA: 0s - loss: 0.0165 - mse: 0.0099\n",
      "Epoch 00012: val_mse did not improve from 0.00962\n",
      "7248/7248 [==============================] - 1s 72us/sample - loss: 0.0162 - mse: 0.0097 - val_loss: 0.0156 - val_mse: 0.0098\n",
      "Epoch 13/1000\n",
      "7040/7248 [============================>.] - ETA: 0s - loss: 0.0149 - mse: 0.0096\n",
      "Epoch 00013: val_mse did not improve from 0.00962\n",
      "7248/7248 [==============================] - 1s 74us/sample - loss: 0.0148 - mse: 0.0096 - val_loss: 0.0145 - val_mse: 0.0098\n",
      "Epoch 14/1000\n",
      "6912/7248 [===========================>..] - ETA: 0s - loss: 0.0138 - mse: 0.0096\n",
      "Epoch 00014: val_mse did not improve from 0.00962\n",
      "7248/7248 [==============================] - 1s 76us/sample - loss: 0.0138 - mse: 0.0096 - val_loss: 0.0137 - val_mse: 0.0098\n",
      "Epoch 15/1000\n",
      "6400/7248 [=========================>....] - ETA: 0s - loss: 0.0131 - mse: 0.0095\n",
      "Epoch 00015: val_mse did not improve from 0.00962\n",
      "7248/7248 [==============================] - 1s 72us/sample - loss: 0.0130 - mse: 0.0094 - val_loss: 0.0130 - val_mse: 0.0098\n",
      "Epoch 16/1000\n",
      "7168/7248 [============================>.] - ETA: 0s - loss: 0.0123 - mse: 0.0094\n",
      "Epoch 00016: val_mse did not improve from 0.00962\n",
      "7248/7248 [==============================] - 1s 73us/sample - loss: 0.0123 - mse: 0.0094 - val_loss: 0.0125 - val_mse: 0.0098\n",
      "Epoch 17/1000\n",
      "7104/7248 [============================>.] - ETA: 0s - loss: 0.0118 - mse: 0.0093\n",
      "Epoch 00017: val_mse did not improve from 0.00962\n",
      "7248/7248 [==============================] - 1s 73us/sample - loss: 0.0118 - mse: 0.0093 - val_loss: 0.0120 - val_mse: 0.0097\n",
      "Epoch 18/1000\n",
      "7104/7248 [============================>.] - ETA: 0s - loss: 0.0115 - mse: 0.0093\n",
      "Epoch 00018: val_mse improved from 0.00962 to 0.00962, saving model to best_model.h5\n",
      "7248/7248 [==============================] - 1s 77us/sample - loss: 0.0114 - mse: 0.0092 - val_loss: 0.0116 - val_mse: 0.0096\n",
      "Epoch 19/1000\n",
      "7168/7248 [============================>.] - ETA: 0s - loss: 0.0110 - mse: 0.0091\n",
      "Epoch 00019: val_mse improved from 0.00962 to 0.00948, saving model to best_model.h5\n",
      "7248/7248 [==============================] - 1s 76us/sample - loss: 0.0110 - mse: 0.0091 - val_loss: 0.0112 - val_mse: 0.0095\n",
      "Epoch 20/1000\n",
      "7040/7248 [============================>.] - ETA: 0s - loss: 0.0107 - mse: 0.0091\n",
      "Epoch 00020: val_mse improved from 0.00948 to 0.00939, saving model to best_model.h5\n",
      "7248/7248 [==============================] - 1s 77us/sample - loss: 0.0107 - mse: 0.0091 - val_loss: 0.0109 - val_mse: 0.0094\n",
      "Epoch 21/1000\n",
      "6464/7248 [=========================>....] - ETA: 0s - loss: 0.0102 - mse: 0.0088\n",
      "Epoch 00021: val_mse improved from 0.00939 to 0.00917, saving model to best_model.h5\n",
      "7248/7248 [==============================] - 1s 75us/sample - loss: 0.0104 - mse: 0.0089 - val_loss: 0.0106 - val_mse: 0.0092\n",
      "Epoch 22/1000\n",
      "7168/7248 [============================>.] - ETA: 0s - loss: 0.0100 - mse: 0.0087\n",
      "Epoch 00022: val_mse improved from 0.00917 to 0.00887, saving model to best_model.h5\n",
      "7248/7248 [==============================] - 1s 76us/sample - loss: 0.0101 - mse: 0.0087 - val_loss: 0.0102 - val_mse: 0.0089\n",
      "Epoch 23/1000\n",
      "6912/7248 [===========================>..] - ETA: 0s - loss: 0.0096 - mse: 0.0083\n",
      "Epoch 00023: val_mse improved from 0.00887 to 0.00865, saving model to best_model.h5\n",
      "7248/7248 [==============================] - 1s 77us/sample - loss: 0.0098 - mse: 0.0085 - val_loss: 0.0099 - val_mse: 0.0087\n",
      "Epoch 24/1000\n",
      "7168/7248 [============================>.] - ETA: 0s - loss: 0.0097 - mse: 0.0086\n",
      "Epoch 00024: val_mse improved from 0.00865 to 0.00864, saving model to best_model.h5\n",
      "7248/7248 [==============================] - 1s 75us/sample - loss: 0.0097 - mse: 0.0086 - val_loss: 0.0097 - val_mse: 0.0086\n",
      "Epoch 25/1000\n",
      "7104/7248 [============================>.] - ETA: 0s - loss: 0.0095 - mse: 0.0085\n",
      "Epoch 00025: val_mse did not improve from 0.00864\n",
      "7248/7248 [==============================] - 1s 74us/sample - loss: 0.0095 - mse: 0.0085 - val_loss: 0.0096 - val_mse: 0.0087\n",
      "Epoch 26/1000\n",
      "7104/7248 [============================>.] - ETA: 0s - loss: 0.0093 - mse: 0.0084\n",
      "Epoch 00026: val_mse improved from 0.00864 to 0.00858, saving model to best_model.h5\n",
      "7248/7248 [==============================] - 1s 76us/sample - loss: 0.0094 - mse: 0.0085 - val_loss: 0.0094 - val_mse: 0.0086\n",
      "Epoch 27/1000\n",
      "6976/7248 [===========================>..] - ETA: 0s - loss: 0.0093 - mse: 0.0085\n",
      "Epoch 00027: val_mse improved from 0.00858 to 0.00852, saving model to best_model.h5\n",
      "7248/7248 [==============================] - 1s 78us/sample - loss: 0.0093 - mse: 0.0085 - val_loss: 0.0094 - val_mse: 0.0085\n",
      "Epoch 28/1000\n",
      "6816/7248 [===========================>..] - ETA: 0s - loss: 0.0089 - mse: 0.0080\n",
      "Epoch 00028: val_mse improved from 0.00852 to 0.00817, saving model to best_model.h5\n",
      "7248/7248 [==============================] - 1s 90us/sample - loss: 0.0089 - mse: 0.0080 - val_loss: 0.0091 - val_mse: 0.0082\n",
      "Epoch 29/1000\n",
      "6560/7248 [==========================>...] - ETA: 0s - loss: 0.0089 - mse: 0.0080\n",
      "Epoch 00029: val_mse did not improve from 0.00817\n",
      "7248/7248 [==============================] - 1s 78us/sample - loss: 0.0090 - mse: 0.0082 - val_loss: 0.0090 - val_mse: 0.0082\n",
      "Epoch 30/1000\n",
      "6944/7248 [===========================>..] - ETA: 0s - loss: 0.0088 - mse: 0.0080\n",
      "Epoch 00030: val_mse improved from 0.00817 to 0.00791, saving model to best_model.h5\n",
      "7248/7248 [==============================] - 1s 81us/sample - loss: 0.0088 - mse: 0.0080 - val_loss: 0.0088 - val_mse: 0.0079\n",
      "Epoch 31/1000\n",
      "7136/7248 [============================>.] - ETA: 0s - loss: 0.0090 - mse: 0.0082\n",
      "Epoch 00031: val_mse did not improve from 0.00791\n",
      "7248/7248 [==============================] - 1s 73us/sample - loss: 0.0089 - mse: 0.0081 - val_loss: 0.0090 - val_mse: 0.0083\n",
      "Epoch 32/1000\n",
      "7104/7248 [============================>.] - ETA: 0s - loss: 0.0088 - mse: 0.0080\n",
      "Epoch 00032: val_mse did not improve from 0.00791\n",
      "7248/7248 [==============================] - 1s 73us/sample - loss: 0.0088 - mse: 0.0081 - val_loss: 0.0088 - val_mse: 0.0081\n",
      "Epoch 33/1000\n",
      "7200/7248 [============================>.] - ETA: 0s - loss: 0.0087 - mse: 0.0080\n",
      "Epoch 00033: val_mse improved from 0.00791 to 0.00784, saving model to best_model.h5\n",
      "7248/7248 [==============================] - 1s 76us/sample - loss: 0.0087 - mse: 0.0080 - val_loss: 0.0086 - val_mse: 0.0078\n",
      "Epoch 34/1000\n",
      "6528/7248 [==========================>...] - ETA: 0s - loss: 0.0086 - mse: 0.0078\n",
      "Epoch 00034: val_mse did not improve from 0.00784\n",
      "7248/7248 [==============================] - 1s 78us/sample - loss: 0.0087 - mse: 0.0079 - val_loss: 0.0087 - val_mse: 0.0080\n",
      "Epoch 35/1000\n",
      "7200/7248 [============================>.] - ETA: 0s - loss: 0.0089 - mse: 0.0082\n",
      "Epoch 00035: val_mse did not improve from 0.00784\n",
      "7248/7248 [==============================] - 1s 73us/sample - loss: 0.0089 - mse: 0.0082 - val_loss: 0.0087 - val_mse: 0.0081\n",
      "Epoch 36/1000\n",
      "6688/7248 [==========================>...] - ETA: 0s - loss: 0.0087 - mse: 0.0080\n",
      "Epoch 00036: val_mse did not improve from 0.00784\n",
      "7248/7248 [==============================] - 1s 80us/sample - loss: 0.0087 - mse: 0.0080 - val_loss: 0.0087 - val_mse: 0.0080\n",
      "Epoch 37/1000\n",
      "6560/7248 [==========================>...] - ETA: 0s - loss: 0.0089 - mse: 0.0083\n",
      "Epoch 00037: val_mse did not improve from 0.00784\n",
      "7248/7248 [==============================] - 1s 79us/sample - loss: 0.0088 - mse: 0.0082 - val_loss: 0.0086 - val_mse: 0.0079\n",
      "Epoch 38/1000\n",
      "6432/7248 [=========================>....] - ETA: 0s - loss: 0.0090 - mse: 0.0084\n",
      "Epoch 00038: val_mse did not improve from 0.00784\n",
      "7248/7248 [==============================] - 1s 79us/sample - loss: 0.0089 - mse: 0.0083 - val_loss: 0.0088 - val_mse: 0.0082\n",
      "Epoch 39/1000\n",
      "6976/7248 [===========================>..] - ETA: 0s - loss: 0.0087 - mse: 0.0081\n",
      "Epoch 00039: val_mse did not improve from 0.00784\n",
      "7248/7248 [==============================] - 1s 75us/sample - loss: 0.0087 - mse: 0.0080 - val_loss: 0.0085 - val_mse: 0.0079\n",
      "Epoch 40/1000\n",
      "7168/7248 [============================>.] - ETA: 0s - loss: 0.0087 - mse: 0.0081\n",
      "Epoch 00040: val_mse did not improve from 0.00784\n",
      "7248/7248 [==============================] - 1s 76us/sample - loss: 0.0087 - mse: 0.0081 - val_loss: 0.0085 - val_mse: 0.0079\n",
      "Epoch 41/1000\n",
      "6592/7248 [==========================>...] - ETA: 0s - loss: 0.0086 - mse: 0.0079\n",
      "Epoch 00041: val_mse improved from 0.00784 to 0.00782, saving model to best_model.h5\n",
      "7248/7248 [==============================] - 1s 81us/sample - loss: 0.0088 - mse: 0.0082 - val_loss: 0.0084 - val_mse: 0.0078\n",
      "Epoch 42/1000\n",
      "7008/7248 [============================>.] - ETA: 0s - loss: 0.0085 - mse: 0.0079\n",
      "Epoch 00042: val_mse improved from 0.00782 to 0.00776, saving model to best_model.h5\n",
      "7248/7248 [==============================] - 1s 79us/sample - loss: 0.0085 - mse: 0.0079 - val_loss: 0.0084 - val_mse: 0.0078\n",
      "Epoch 43/1000\n",
      "7104/7248 [============================>.] - ETA: 0s - loss: 0.0087 - mse: 0.0081\n",
      "Epoch 00043: val_mse improved from 0.00776 to 0.00773, saving model to best_model.h5\n",
      "7248/7248 [==============================] - 1s 77us/sample - loss: 0.0086 - mse: 0.0080 - val_loss: 0.0083 - val_mse: 0.0077\n",
      "Epoch 44/1000\n",
      "6816/7248 [===========================>..] - ETA: 0s - loss: 0.0084 - mse: 0.0078\n",
      "Epoch 00044: val_mse did not improve from 0.00773\n",
      "7248/7248 [==============================] - 1s 77us/sample - loss: 0.0085 - mse: 0.0079 - val_loss: 0.0084 - val_mse: 0.0078\n",
      "Epoch 45/1000\n",
      "6816/7248 [===========================>..] - ETA: 0s - loss: 0.0086 - mse: 0.0080\n",
      "Epoch 00045: val_mse did not improve from 0.00773\n",
      "7248/7248 [==============================] - 1s 76us/sample - loss: 0.0085 - mse: 0.0079 - val_loss: 0.0083 - val_mse: 0.0078\n",
      "Epoch 46/1000\n",
      "7104/7248 [============================>.] - ETA: 0s - loss: 0.0085 - mse: 0.0079\n",
      "Epoch 00046: val_mse improved from 0.00773 to 0.00761, saving model to best_model.h5\n",
      "7248/7248 [==============================] - 1s 76us/sample - loss: 0.0085 - mse: 0.0079 - val_loss: 0.0083 - val_mse: 0.0076\n",
      "Epoch 47/1000\n",
      "7008/7248 [============================>.] - ETA: 0s - loss: 0.0086 - mse: 0.0081\n",
      "Epoch 00047: val_mse did not improve from 0.00761\n",
      "7248/7248 [==============================] - 1s 75us/sample - loss: 0.0086 - mse: 0.0081 - val_loss: 0.0083 - val_mse: 0.0077\n",
      "Epoch 48/1000\n",
      "7008/7248 [============================>.] - ETA: 0s - loss: 0.0082 - mse: 0.0076\n",
      "Epoch 00048: val_mse improved from 0.00761 to 0.00740, saving model to best_model.h5\n",
      "7248/7248 [==============================] - 1s 77us/sample - loss: 0.0083 - mse: 0.0076 - val_loss: 0.0081 - val_mse: 0.0074\n",
      "Epoch 49/1000\n",
      "6816/7248 [===========================>..] - ETA: 0s - loss: 0.0083 - mse: 0.0077\n",
      "Epoch 00049: val_mse did not improve from 0.00740\n",
      "7248/7248 [==============================] - 1s 76us/sample - loss: 0.0084 - mse: 0.0078 - val_loss: 0.0082 - val_mse: 0.0076\n",
      "Epoch 50/1000\n",
      "6816/7248 [===========================>..] - ETA: 0s - loss: 0.0087 - mse: 0.0082\n",
      "Epoch 00050: val_mse did not improve from 0.00740\n",
      "7248/7248 [==============================] - 1s 79us/sample - loss: 0.0085 - mse: 0.0080 - val_loss: 0.0085 - val_mse: 0.0079\n",
      "Epoch 51/1000\n",
      "6816/7248 [===========================>..] - ETA: 0s - loss: 0.0085 - mse: 0.0080\n",
      "Epoch 00051: val_mse did not improve from 0.00740\n",
      "7248/7248 [==============================] - 1s 77us/sample - loss: 0.0084 - mse: 0.0079 - val_loss: 0.0084 - val_mse: 0.0078\n",
      "Epoch 52/1000\n",
      "6880/7248 [===========================>..] - ETA: 0s - loss: 0.0084 - mse: 0.0078\n",
      "Epoch 00052: val_mse did not improve from 0.00740\n",
      "7248/7248 [==============================] - 1s 76us/sample - loss: 0.0085 - mse: 0.0079 - val_loss: 0.0083 - val_mse: 0.0077\n",
      "Epoch 53/1000\n",
      "7104/7248 [============================>.] - ETA: 0s - loss: 0.0085 - mse: 0.0080\n",
      "Epoch 00053: val_mse did not improve from 0.00740\n",
      "7248/7248 [==============================] - 1s 74us/sample - loss: 0.0085 - mse: 0.0080 - val_loss: 0.0082 - val_mse: 0.0076\n",
      "Epoch 54/1000\n",
      "6688/7248 [==========================>...] - ETA: 0s - loss: 0.0083 - mse: 0.0077\n",
      "Epoch 00054: val_mse did not improve from 0.00740\n",
      "7248/7248 [==============================] - 1s 78us/sample - loss: 0.0084 - mse: 0.0078 - val_loss: 0.0080 - val_mse: 0.0074\n",
      "Epoch 55/1000\n",
      "6656/7248 [==========================>...] - ETA: 0s - loss: 0.0082 - mse: 0.0076\n",
      "Epoch 00055: val_mse did not improve from 0.00740\n",
      "7248/7248 [==============================] - 1s 77us/sample - loss: 0.0083 - mse: 0.0077 - val_loss: 0.0081 - val_mse: 0.0076\n",
      "Epoch 56/1000\n",
      "6976/7248 [===========================>..] - ETA: 0s - loss: 0.0084 - mse: 0.0078\n",
      "Epoch 00056: val_mse did not improve from 0.00740\n",
      "7248/7248 [==============================] - 1s 74us/sample - loss: 0.0084 - mse: 0.0079 - val_loss: 0.0080 - val_mse: 0.0074\n",
      "Epoch 57/1000\n",
      "7040/7248 [============================>.] - ETA: 0s - loss: 0.0083 - mse: 0.0078\n",
      "Epoch 00057: val_mse did not improve from 0.00740\n",
      "7248/7248 [==============================] - 1s 74us/sample - loss: 0.0084 - mse: 0.0079 - val_loss: 0.0081 - val_mse: 0.0076\n",
      "Epoch 58/1000\n",
      "7104/7248 [============================>.] - ETA: 0s - loss: 0.0084 - mse: 0.0079\n",
      "Epoch 00058: val_mse did not improve from 0.00740\n",
      "7248/7248 [==============================] - 1s 75us/sample - loss: 0.0085 - mse: 0.0080 - val_loss: 0.0080 - val_mse: 0.0075\n",
      "Epoch 59/1000\n",
      "7104/7248 [============================>.] - ETA: 0s - loss: 0.0084 - mse: 0.0078\n",
      "Epoch 00059: val_mse did not improve from 0.00740\n",
      "7248/7248 [==============================] - 1s 74us/sample - loss: 0.0084 - mse: 0.0078 - val_loss: 0.0079 - val_mse: 0.0074\n",
      "Epoch 60/1000\n",
      "7200/7248 [============================>.] - ETA: 0s - loss: 0.0085 - mse: 0.0080\n",
      "Epoch 00060: val_mse did not improve from 0.00740\n",
      "7248/7248 [==============================] - 1s 73us/sample - loss: 0.0085 - mse: 0.0080 - val_loss: 0.0080 - val_mse: 0.0075\n",
      "Epoch 61/1000\n",
      "7104/7248 [============================>.] - ETA: 0s - loss: 0.0083 - mse: 0.0078\n",
      "Epoch 00061: val_mse did not improve from 0.00740\n",
      "7248/7248 [==============================] - 1s 74us/sample - loss: 0.0083 - mse: 0.0078 - val_loss: 0.0080 - val_mse: 0.0075\n",
      "Epoch 62/1000\n",
      "7136/7248 [============================>.] - ETA: 0s - loss: 0.0083 - mse: 0.0078\n",
      "Epoch 00062: val_mse did not improve from 0.00740\n",
      "7248/7248 [==============================] - 1s 73us/sample - loss: 0.0084 - mse: 0.0079 - val_loss: 0.0083 - val_mse: 0.0078\n",
      "Epoch 63/1000\n",
      "6752/7248 [==========================>...] - ETA: 0s - loss: 0.0085 - mse: 0.0080\n",
      "Epoch 00063: val_mse did not improve from 0.00740\n",
      "7248/7248 [==============================] - 1s 77us/sample - loss: 0.0085 - mse: 0.0080 - val_loss: 0.0083 - val_mse: 0.0079\n",
      "Epoch 64/1000\n",
      "7232/7248 [============================>.] - ETA: 0s - loss: 0.0083 - mse: 0.0078\n",
      "Epoch 00064: val_mse did not improve from 0.00740\n",
      "7248/7248 [==============================] - 1s 73us/sample - loss: 0.0083 - mse: 0.0078 - val_loss: 0.0081 - val_mse: 0.0075\n",
      "Epoch 65/1000\n",
      "7200/7248 [============================>.] - ETA: 0s - loss: 0.0084 - mse: 0.0079\n",
      "Epoch 00065: val_mse improved from 0.00740 to 0.00734, saving model to best_model.h5\n",
      "7248/7248 [==============================] - 1s 76us/sample - loss: 0.0084 - mse: 0.0079 - val_loss: 0.0079 - val_mse: 0.0073\n",
      "Epoch 66/1000\n",
      "6368/7248 [=========================>....] - ETA: 0s - loss: 0.0085 - mse: 0.0080\n",
      "Epoch 00066: val_mse did not improve from 0.00734\n",
      "7248/7248 [==============================] - 1s 72us/sample - loss: 0.0084 - mse: 0.0079 - val_loss: 0.0079 - val_mse: 0.0075\n",
      "Epoch 67/1000\n",
      "7232/7248 [============================>.] - ETA: 0s - loss: 0.0082 - mse: 0.0077\n",
      "Epoch 00067: val_mse did not improve from 0.00734\n",
      "7248/7248 [==============================] - 1s 72us/sample - loss: 0.0082 - mse: 0.0077 - val_loss: 0.0082 - val_mse: 0.0078\n",
      "Epoch 68/1000\n",
      "7232/7248 [============================>.] - ETA: 0s - loss: 0.0083 - mse: 0.0078\n",
      "Epoch 00068: val_mse did not improve from 0.00734\n",
      "7248/7248 [==============================] - 1s 72us/sample - loss: 0.0083 - mse: 0.0078 - val_loss: 0.0081 - val_mse: 0.0076\n",
      "Epoch 69/1000\n",
      "7136/7248 [============================>.] - ETA: 0s - loss: 0.0083 - mse: 0.0078\n",
      "Epoch 00069: val_mse did not improve from 0.00734\n",
      "7248/7248 [==============================] - 1s 73us/sample - loss: 0.0083 - mse: 0.0078 - val_loss: 0.0082 - val_mse: 0.0077\n",
      "Epoch 70/1000\n",
      "7104/7248 [============================>.] - ETA: 0s - loss: 0.0084 - mse: 0.0079\n",
      "Epoch 00070: val_mse did not improve from 0.00734\n",
      "7248/7248 [==============================] - 1s 74us/sample - loss: 0.0084 - mse: 0.0079 - val_loss: 0.0083 - val_mse: 0.0079\n",
      "Epoch 71/1000\n",
      "7200/7248 [============================>.] - ETA: 0s - loss: 0.0083 - mse: 0.0078\n",
      "Epoch 00071: val_mse improved from 0.00734 to 0.00730, saving model to best_model.h5\n",
      "7248/7248 [==============================] - 1s 76us/sample - loss: 0.0083 - mse: 0.0078 - val_loss: 0.0078 - val_mse: 0.0073\n",
      "Epoch 72/1000\n",
      "7104/7248 [============================>.] - ETA: 0s - loss: 0.0084 - mse: 0.0079\n",
      "Epoch 00072: val_mse did not improve from 0.00730\n",
      "7248/7248 [==============================] - 1s 73us/sample - loss: 0.0083 - mse: 0.0078 - val_loss: 0.0082 - val_mse: 0.0077\n",
      "Epoch 73/1000\n",
      "7232/7248 [============================>.] - ETA: 0s - loss: 0.0081 - mse: 0.0076\n",
      "Epoch 00073: val_mse did not improve from 0.00730\n",
      "7248/7248 [==============================] - 1s 73us/sample - loss: 0.0081 - mse: 0.0076 - val_loss: 0.0081 - val_mse: 0.0076\n",
      "Epoch 74/1000\n",
      "6592/7248 [==========================>...] - ETA: 0s - loss: 0.0080 - mse: 0.0076\n",
      "Epoch 00074: val_mse did not improve from 0.00730\n",
      "7248/7248 [==============================] - 1s 79us/sample - loss: 0.0082 - mse: 0.0077 - val_loss: 0.0079 - val_mse: 0.0073\n",
      "Epoch 75/1000\n",
      "7072/7248 [============================>.] - ETA: 0s - loss: 0.0083 - mse: 0.0078\n",
      "Epoch 00075: val_mse did not improve from 0.00730\n",
      "7248/7248 [==============================] - 1s 74us/sample - loss: 0.0082 - mse: 0.0077 - val_loss: 0.0079 - val_mse: 0.0075\n",
      "Epoch 76/1000\n",
      "7008/7248 [============================>.] - ETA: 0s - loss: 0.0080 - mse: 0.0075\n",
      "Epoch 00076: val_mse did not improve from 0.00730\n",
      "7248/7248 [==============================] - 1s 73us/sample - loss: 0.0081 - mse: 0.0076 - val_loss: 0.0079 - val_mse: 0.0075\n",
      "Epoch 77/1000\n",
      "6432/7248 [=========================>....] - ETA: 0s - loss: 0.0083 - mse: 0.0078\n",
      "Epoch 00077: val_mse did not improve from 0.00730\n",
      "7248/7248 [==============================] - 1s 71us/sample - loss: 0.0083 - mse: 0.0078 - val_loss: 0.0082 - val_mse: 0.0077\n",
      "Epoch 78/1000\n",
      "7104/7248 [============================>.] - ETA: 0s - loss: 0.0082 - mse: 0.0077\n",
      "Epoch 00078: val_mse improved from 0.00730 to 0.00721, saving model to best_model.h5\n",
      "7248/7248 [==============================] - 1s 76us/sample - loss: 0.0083 - mse: 0.0078 - val_loss: 0.0077 - val_mse: 0.0072\n",
      "Epoch 79/1000\n",
      "7072/7248 [============================>.] - ETA: 0s - loss: 0.0082 - mse: 0.0078\n",
      "Epoch 00079: val_mse did not improve from 0.00721\n",
      "7248/7248 [==============================] - 1s 73us/sample - loss: 0.0083 - mse: 0.0078 - val_loss: 0.0079 - val_mse: 0.0074\n",
      "Epoch 80/1000\n",
      "7200/7248 [============================>.] - ETA: 0s - loss: 0.0084 - mse: 0.0079\n",
      "Epoch 00080: val_mse did not improve from 0.00721\n",
      "7248/7248 [==============================] - 1s 73us/sample - loss: 0.0084 - mse: 0.0079 - val_loss: 0.0078 - val_mse: 0.0073\n",
      "Epoch 81/1000\n",
      "7168/7248 [============================>.] - ETA: 0s - loss: 0.0082 - mse: 0.0077\n",
      "Epoch 00081: val_mse did not improve from 0.00721\n",
      "7248/7248 [==============================] - 1s 73us/sample - loss: 0.0082 - mse: 0.0077 - val_loss: 0.0079 - val_mse: 0.0074\n",
      "Epoch 82/1000\n",
      "7040/7248 [============================>.] - ETA: 0s - loss: 0.0080 - mse: 0.0074\n",
      "Epoch 00082: val_mse did not improve from 0.00721\n",
      "7248/7248 [==============================] - 1s 74us/sample - loss: 0.0080 - mse: 0.0075 - val_loss: 0.0077 - val_mse: 0.0072\n",
      "Epoch 83/1000\n",
      "7200/7248 [============================>.] - ETA: 0s - loss: 0.0082 - mse: 0.0077\n",
      "Epoch 00083: val_mse did not improve from 0.00721\n",
      "7248/7248 [==============================] - 1s 73us/sample - loss: 0.0082 - mse: 0.0078 - val_loss: 0.0079 - val_mse: 0.0074\n",
      "Epoch 84/1000\n",
      "7040/7248 [============================>.] - ETA: 0s - loss: 0.0082 - mse: 0.0077\n",
      "Epoch 00084: val_mse did not improve from 0.00721\n",
      "7248/7248 [==============================] - 1s 74us/sample - loss: 0.0082 - mse: 0.0078 - val_loss: 0.0080 - val_mse: 0.0075\n",
      "Epoch 85/1000\n",
      "7136/7248 [============================>.] - ETA: 0s - loss: 0.0082 - mse: 0.0078\n",
      "Epoch 00085: val_mse did not improve from 0.00721\n",
      "7248/7248 [==============================] - 1s 73us/sample - loss: 0.0082 - mse: 0.0078 - val_loss: 0.0080 - val_mse: 0.0075\n",
      "Epoch 86/1000\n",
      "6752/7248 [==========================>...] - ETA: 0s - loss: 0.0082 - mse: 0.0077\n",
      "Epoch 00086: val_mse did not improve from 0.00721\n",
      "7248/7248 [==============================] - 1s 75us/sample - loss: 0.0083 - mse: 0.0078 - val_loss: 0.0081 - val_mse: 0.0077\n",
      "Epoch 87/1000\n",
      "6400/7248 [=========================>....] - ETA: 0s - loss: 0.0083 - mse: 0.0079\n",
      "Epoch 00087: val_mse did not improve from 0.00721\n",
      "7248/7248 [==============================] - 1s 72us/sample - loss: 0.0083 - mse: 0.0078 - val_loss: 0.0080 - val_mse: 0.0075\n",
      "Epoch 88/1000\n",
      "6336/7248 [=========================>....] - ETA: 0s - loss: 0.0081 - mse: 0.0076\n",
      "Epoch 00088: val_mse did not improve from 0.00721\n",
      "7248/7248 [==============================] - 1s 73us/sample - loss: 0.0081 - mse: 0.0076 - val_loss: 0.0080 - val_mse: 0.0075\n",
      "Epoch 89/1000\n",
      "6400/7248 [=========================>....] - ETA: 0s - loss: 0.0080 - mse: 0.0076\n",
      "Epoch 00089: val_mse did not improve from 0.00721\n",
      "7248/7248 [==============================] - 1s 72us/sample - loss: 0.0080 - mse: 0.0076 - val_loss: 0.0080 - val_mse: 0.0075\n",
      "Epoch 90/1000\n",
      "7136/7248 [============================>.] - ETA: 0s - loss: 0.0083 - mse: 0.0079\n",
      "Epoch 00090: val_mse did not improve from 0.00721\n",
      "7248/7248 [==============================] - 1s 73us/sample - loss: 0.0083 - mse: 0.0079 - val_loss: 0.0078 - val_mse: 0.0074\n",
      "Epoch 91/1000\n",
      "7136/7248 [============================>.] - ETA: 0s - loss: 0.0083 - mse: 0.0079\n",
      "Epoch 00091: val_mse did not improve from 0.00721\n",
      "7248/7248 [==============================] - 1s 73us/sample - loss: 0.0083 - mse: 0.0078 - val_loss: 0.0081 - val_mse: 0.0077\n",
      "Epoch 92/1000\n",
      "7232/7248 [============================>.] - ETA: 0s - loss: 0.0083 - mse: 0.0078\n",
      "Epoch 00092: val_mse did not improve from 0.00721\n",
      "7248/7248 [==============================] - 1s 72us/sample - loss: 0.0083 - mse: 0.0078 - val_loss: 0.0080 - val_mse: 0.0076\n",
      "Epoch 00092: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f639c5bcf28>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs = 1000, validation_data = (X_test, y_test), callbacks = [es, mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model = tf.keras.models.load_model('best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2417/2417 - 0s - loss: 0.0077 - mse: 0.0072\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.00774691671309904, 0.0072109546]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saved_model.evaluate(X_test, y_test, verbose = 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
